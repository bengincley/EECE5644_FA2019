%% Midterm Exam, Question 1
% EECE5644
% Code generated by Benjamin Gincley
% 13 October 2019
%% Question 1
rng(5);
%% Generate Data
m(:,1) = [-1;0]; Sigma(:,:,1) = 0.1*[10 -4;-4,5]; % mean and covariance of data pdf conditioned on label 3
m(:,2) = [1;0]; Sigma(:,:,2) = 0.1*[5 0;0,2]; % mean and covariance of data pdf conditioned on label 2
m(:,3) = [0;1]; Sigma(:,:,3) = 0.1*eye(2); % mean and covariance of data pdf conditioned on label 1
classPriors = [0.15,0.35,0.5]; thr = [0,cumsum(classPriors)];
N = 10000; u = rand(1,N); labels = zeros(1,N); x = zeros(2,N);
figure(1),clf, colorList = ['r','b','g'];
n_samples = zeros(1,3);
for l = 1:3
    indices = find(thr(l)<=u & u<thr(l+1)); % if u happens to be precisely 1, that sample will get omitted - needs to be fixed
    n_samples(:,l) = size(indices,2);
    labels(1,indices) = l*ones(1,length(indices));
    x(:,indices) = mvnrnd(m(:,l),Sigma(:,:,l),length(indices))';
    figure(1), plot(x(1,indices),x(2,indices),'.','MarkerFaceColor',colorList(l)); axis equal, hold on,
end
%% Classifier - Bayes
% likelihood1 = mvnpdf(x(:,labels==1)',m(:,1)',Sigma(:,:,1));
% likelihood2 = mvnpdf(x(:,labels==2)',m(:,2)',Sigma(:,:,2));
% likelihood3 = mvnpdf(x(:,labels==3)',m(:,3)',Sigma(:,:,3));
likelihood1 = mvnpdf(x',m(:,1)',Sigma(:,:,1));
likelihood2 = mvnpdf(x',m(:,2)',Sigma(:,:,2));
likelihood3 = mvnpdf(x',m(:,3)',Sigma(:,:,3));

% figure()
% hold on
% % scatter(1:n_samples(1),likelihood1)
% % scatter(n_samples(1)+1:n_samples(1)+n_samples(2),likelihood2)
% % scatter(n_samples(1)+n_samples(2)+1:n_samples(1)+n_samples(2)+n_samples(3),likelihood3)
% scatter(1:N,likelihood1)
% scatter(1:N,likelihood2)
% scatter(1:N,likelihood3)
Posterior(:,1) = likelihood1 * classPriors(1);
Posterior(:,2) = likelihood2 * classPriors(2);
Posterior(:,3) = likelihood3 * classPriors(3);
[val, MAP_predict] = max(Posterior,[],2);
MAP_predict = MAP_predict';
tot_loss_MAP = sum(MAP_predict ~= labels)/N;

%% Naive Bayes
cp = cvpartition(labels,'Holdout',0.3);
trainidx = cp.training';
testidx = cp.test';
trainData = x(:,trainidx)';
testData = x(:,testidx)';
trainLabels = labels(:,trainidx)';
testLabels = labels(:,testidx)';

nbclassifier = fitcnb(trainData,trainLabels,'Prior',classPriors);
predictions = predict(nbclassifier,testData);

resubloss = resubLoss(nbclassifier);
testloss = sum(predictions ~= testLabels)/N;
fullPredictions = predict(nbclassifier,x');
tot_loss_NB = sum(fullPredictions ~= labels')/N
incorrectLabels = fullPredictions ~= labels';
figure()
cmChart = confusionchart(labels',fullPredictions);
cm = confusionmat(labels',fullPredictions)' % flipped so true labels are columns
%% Plot
figure(); hold on;
scatter(x(1,labels==1),x(2,labels==1),'k+')
scatter(x(1,labels==2),x(2,labels==2),'g+')
scatter(x(1,labels==3),x(2,labels==3),'b+')
scatter(x(1,fullPredictions==1),x(2,fullPredictions==1),'ko')
scatter(x(1,fullPredictions==2),x(2,fullPredictions==2),'go')
scatter(x(1,fullPredictions==3),x(2,fullPredictions==3),'bo')
scatter(x(1,incorrectLabels==1),x(2,incorrectLabels==1),'rx')
lgd = legend('True Class 1', 'True Class 2', 'True Class 3', 'Predicted Class 1', ...
    'Predicted Class 2', 'Predicted Class 3','Misclassified');
lgd.Location = 'southwest';
xlabel('x1')
ylabel('x2')
title(sprintf('Bayes Classifier Predictions for 3-Class Multivariate Distribution. Error Rate = %.3f', tot_loss_NB))